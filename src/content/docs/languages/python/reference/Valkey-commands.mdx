---
title: Valkey commands
description: A reference page in my new Starlight docs site.
---

import { Aside } from '@astrojs/starlight/components';

<Aside type="caution" title="Work In Progress!">
This documentation site is under construction and is not yet complete!

For official Valkey GLIDE documentation, please refer to the official [Valkey GLIDE](https://github.com/valkey-io/valkey-glide) Github.
</Aside>


## Valkey commands
For information on the supported commands and their corresponding parameters, we recommend referring to the documentation in the code. This documentation provides in-depth insights into the usage and options available for each command.

### Batch: Transaction and Pipelining (Glide 2.0)

In Valkey Glide 2.0, the concept of **Batch** and **ClusterBatch** replaces the previous **Transaction** and **ClusterTransaction** APIs. 
This change provides greater flexibility by supporting both **atomic batches** (Transactions) and **non-atomic batches** (Pipelining), while ensuring easy configuration and clear, detailed examples for each scenario.

#### Overview
Glide 2.0 introduces a robust Batch API with two primary modes:

* **Atomic Batch:** Guarantees that all commands in a batch execute as a single, atomic unit. No other commands can interleave (similar to [MULTI](https://valkey.io/commands/multi/)/[EXEC](https://valkey.io/commands/exec/)).
* **Non-Atomic Batch** (Pipeline): Sends multiple commands in one request without atomic guarantees. Commands can span multiple slots/nodes in a cluster and do not block other operations from being processed between them.

Both modes leverage the same classes— `Batch` for standalone mode and `ClusterBatch` for cluster mode — distinguished by an `isAtomic` flag. Extra configuration is provided via `BatchOptions` or `ClusterBatchOptions`, allowing control over timeouts, routings, and retry strategies.

#### Key Concepts

**Atomic Batch (Transaction)**

* **Definition:** A set of commands executed together as a single, indivisible operation.
* **Guarantees:** Sequential execution without interruption. Other clients cannot interleave commands between the batched operations.
* **Slot Constraint** (Cluster Mode): When running against a cluster, all keys in an atomic batch must map to the same hash slot. Mixing keys from different slots will cause the transaction to fail.
* **Underlying Valkey:** Equivalent to [`MULTI`](https://valkey.io/commands/multi/)/[`EXEC`](https://valkey.io/commands/exec/) Valkey commands.
* **Use Case:** When you need consistency and isolation.
* See: [Valkey Transactions](https://valkey.io/topics/transactions/).

**Non-Atomic Batch (Pipeline)**

* Definition: A group of commands sent in a single request, but executed without atomicity or isolation.
* Behavior: Commands may be processed on different slots/nodes (in cluster mode), and other operations from different clients may interleave during execution.
* Underlying Valkey: Similar to pipelining, minimizing round-trip latencies by sending all commands at once.
* Use Case: Bulk reads or writes where each command is independent.
* See: [Valkey Pipelines](https://valkey.io/topics/pipelining/).

#### Classes and API
**`Batch`**

For **standalone** (non-cluster, cluster mode disabled) clients.
```python
from glide import Batch

# Create an atomic batch (transaction)
batch = Batch(True)
# Create a non-atomic batch (pipeline)
batch = Batch(False)
```
> Note: Standalone Batches are executed on primary node.

**`ClusterBatch`**

For **cluster** (cluster mode enabled) clients (Mirrors `Batch` but routes commands based on slot ownership, splitting into sub-pipelines if needed, [Read more in Multi-Node support](https://github.com/valkey-io/valkey-glide/wiki/Python-Wrapper#multi-node-support)). 
```python
from glide import ClusterBatch

# Create an atomic cluster batch (must use keys mapping to same slot)
batch = ClusterBatch(True)
# Create a non-atomic cluster batch (pipeline may span multiple slots)
const batch = ClusterBatch(False)
```
> **Note:** When `isAtomic = true`, all keys in the `ClusterBatch` must map to the same slot. Attempting to include keys from different slots will result in an exception. Read more in [Multi-Node support](https://github.com/valkey-io/valkey-glide/wiki/Python-Wrapper#multi-node-support).
> If the client is configured to read from replicas (ReplicaPrefered, AZ_AFFINITY,  AZ_AFFINITY_REPLICAS_AND_PRIMARY) read commands may be routed to the replicas, in a round robin manner, if this behavior impacts your application, consider creating a dedicated client, with the desired ReadFrom configuration.

**Error handling - `Raise on Error`**

Determines how errors are surfaced when calling `exec(...)`. It is passed directly:
```python
# Standalone Mode
async def exec(
    self,
    batch: Batch,
    raise_on_error: bool,
    options: Optional[BatchOptions] = None,
)

# Cluster Mode
async def exec(
    self,
    batch: ClusterBatch,
    raise_on_error: bool,
    options: Optional[ClusterBatchOptions] = None,
)
```

Behavior:

* `raiseOnError = true`:
When set to `true`, the first encountered error within the batch (after all configured retries and redirections have been executed) is raised as a `RequestException`.

* `raiseOnError = false`:
    * When set to `false`, errors are returned as part of the response array rather than thrown.
    * Each failed command’s error details appear as a `RequestException` instance in the corresponding position of the returned array.
    * Allows processing of both successful and failed commands together.

**Example:**
```python
# Cluster pipeline with raiseOnError = False
batch = ClusterBatch(False)

batch.set(key, "hello")
batch.lpop(key)
batch.delete([key])
batch.rename(key, key2)

result = await GlideClusterClient.exec(batch, raise_on_error=False)
print("Result is:", result)
# Output: Result is: ['OK', RequestError('WRONGTYPE: Operation against a key holding the wrong kind of value'), 1, RequestError('An error was signalled by the server: - ResponseError: no such key')]
```
```python
# Transaction with raiseOnError = true
batch = ClusterBatch(True)

batch.set(key, "hello")
batch.lpop(key)
batch.delete([key])
batch.rename(key, key2)

try: 
    await GlideClient.exec(batch, raise_on_error=False)
except RequestsError as e: 
    print("Batch execution aborted:", e)
# Output: Batch execution aborted: WRONGTYPE: Operation against a key holding the wrong kind of value
```

**`BatchOptions`**

Configuration for **standalone** batches.

| Option    | Type      | Default                                       | Description                                                                                                          |
|-----------|-----------|-----------------------------------------------|---------------------------------------------------|
| `timeout` | `Integer` | Client-level request  timeout (e.g., 5000 ms) | Maximum time in milliseconds to wait for the batch response. If exceeded, a timeout error is returned for the batch. |

```python
from glide import BatchOptions

batch_options = BatchOptions(timeout=2000) # 2 seconds
```

**`ClusterBatchOptions`**

Configuration for cluster batches.

|      Option     |             Type            |            Default            |                                                                            Description                                                                            |
|:---------------:|:---------------------------:|:-----------------------------:|:-----------------------------------------------------------------------------------------------------------------------------------------------------------------:|
|    `timeout`    |          `Integer`          |    Client’s requestTimeout    |                                              Maximum time in milliseconds to wait for entire cluster batch response.                                              |
| `retryStrategy` | `ClusterBatchRetryStrategy` | null (defaults to no retries) | Configures retry settings for server and connection errors. Not supported if<br>`isAtomic = true` — retry strategies only apply to non-atomic (pipeline) batches. |
|     `route`     |      `SingleNodeRoute`      |              null             |                                                       Configures single-node routing for the batch request.                                                       |


**`ClusterBatchRetryStrategy`**

Defines retry behavior (only for **non-atomic** cluster batches). 
|         Option         |    Type   | Default |                                                               Description                                                               |
|:----------------------:|:---------:|:-------:|:---------------------------------------------------------------------------------------------------------------------------------------:|
|   `retryServerError`   | `boolean` | `false` |                 Retry commands that fail with retriable server errors (e.g.`TRYAGAIN`). May cause out-of-order results.                 |
| `retryConnectionError` | `boolean` | `false` | Retry entire batch on connection failures. May cause duplicate executions since server might have processed the request before failure. |

```python
from glide import BatchRetryStrategy

retry_strategy = BatchRetryStrategy(retry_server_error=True, retry_connection_error= False)
```
> **Note:** The ClusterBatchRetryStrategy configuration is only for non-atomic cluster batches, If provided for an atomic cluster batch (a cluster transaction), an error will be thrown.

**Full usage**

```python
from glide import ClusterBatchOptions, BatchRetryStrategy

retry_strategy = BatchRetryStrategy(retry_server_error=True, retry_connection_error=False)
options = ClusterBatchOptions(retry_strategy=retry_strategy)
```

#### Configuration Details
**Timeout**

* Specifies the maximum time (in milliseconds) to wait for the batch (atomic or non-atomic) request to complete.
* If the timeout is reached before receiving all responses, the batch fails with a timeout error.
* Defaults to the client’s `requestTimeout` if not explicitly set.

**Retry Strategies (Cluster Only, Non-Atomic Batches)**

* **Retry on Server Errors**
    * Applies when a command fails with a retriable server error (e.g., `TRYAGAIN`).
    * Glide will automatically retry the failed command on the same node or the new master, depending on the topology update.
    * ⚠️ **Caveat**: Retried commands may arrive later than subsequent commands, leading to out-of-order execution if commands target the same slot.

* **Retry on Connection Errors**
    * If a connection error occurs, the entire batch (or sub-pipeline, [Read more in Multi-Node support](https://github.com/valkey-io/valkey-glide/wiki/Python-Wrapper#multi-node-support))  is retried from the start.
    * ⚠️ **Caveat**: If the server received and processed some or all commands before the connection failure, retrying the batch may lead to duplicate executions.

**Route (Cluster Only)**

Configures single-node routing for the batch request. The client will send the batch to the specified node defined by `route`.
If a redirection error occurs:

* **For Atomic Batches (Transactions):** The entire transaction will be redirected.
* **For Non-Atomic Batches (Pipelines):** only the commands that encountered redirection errors will be redirected.

#### Usage Examples
**Standalone (Atomic Batch)**
```python
from glide import (
 GlideClientConfiguration,
 NodeAddress,
 GlideClient,
 BatchOptions,
)

 # Create client configuration
addresses = [
    NodeAddress("server_primary.example.com", 6379),
    NodeAddress("server_replica.example.com", 6379)
]
config = GlideClientConfiguration(addresses)

 # Initialize client
client = await GlideClient.create(config)

 # Configure batch options
options = BatchOptions(timeout=2000)

# Create atomic batch (true indicates atomic/transaction mode)
atomic_batch = Batch(True)
atomic_batch.set("account:source", "100")
atomic_batch.set("account:dest", "0")
atomic_batch.incrby("account:dest", 50)
atomic_batch.decrby("account:source", 50)
atomic_batch.get("account:source")

try: 
    # Execute with raiseOnError = true
    results = await client.exec(atomic_batch, raise_on_error=True, options=options)
    print("Atomic Batch Results:", results)
    # Expected output: Atomic Batch Results: ['OK', 'OK', 50, 50, '50']
 except RequestError as e:
    print(f"Batch failed:", e)
```
**Standalone (Non-Atomic Batch)**
```python
from glide import (
    GlideClientConfiguration,
    NodeAddress,
    GlideClient,
    Batch,
    BatchOptions
)

# Create client configuration
addresses = [
    NodeAddress("localhost", 6379)
]
config = GlideClientConfiguration(addresses)

# Initialize client
client = await GlideClient.create(config)

# Configure batch options
options = BatchOptions(timeout=2000)  # 2-second timeout

# Create non-atomic batch (False indicates pipeline mode)
pipeline = Batch(False)
pipeline.set("temp:key1", "value1")
pipeline.set("temp:key2", "value2")
pipeline.get("temp:key1")
pipeline.get("temp:key2")

# Execute with raise_on_error = False
results = await client.exec(pipeline, raise_on_error=False, options=options)
print("Pipeline Results:", results)
# Expected output: Pipeline Results: ['OK', 'OK', 'value1', 'value2']
```

**Cluster (Atomic Batch)**
```python
from glide import (
    GlideClusterClientConfiguration,
    NodeAddress,
    GlideClusterClient,
    ClusterBatch,
    ClusterBatchOptions
)

# Initialize cluster client configuration
addresses = [
    NodeAddress("127.0.0.1", 6379)
]
config = GlideClusterClientConfiguration(addresses)

# Initialize client
glideClusterClient = await GlideClusterClient.create(config)

# Configure atomic batch options
options = ClusterBatchOptions(timeout=3000)  # 3-second timeout

# Create atomic cluster batch (all keys map to same slot)
atomicClusterBatch = ClusterBatch(True)
atomicClusterBatch.set("user:100:visits", "1")
atomicClusterBatch.incrby("user:100:visits", 5)
atomicClusterBatch.get("user:100:visits")

try:
    # Execute with raise_on_error = True
    clusterResults = await glideClusterClient.exec(atomicClusterBatch, raise_on_error=True, options=options)
    print("Atomic Cluster Batch:", clusterResults)
    # Expected output: Atomic Cluster Batch: ['OK', 6, '6']
except RequestError as e:
    print("Atomic cluster batch failed:", e)
```
> **Important:** If you attempt to include keys from different slots, the batch creation will throw an exception informing you that keys must map to the same slot when `isAtomic = true`.

**Cluster (Non-Atomic Batch / Pipeline)**
```python
from glide import (
    GlideClusterClientConfiguration,
    NodeAddress,
    GlideClusterClient,
    ClusterBatch,
    ClusterBatchOptions,
    ClusterBatchRetryStrategy
)

# Initialize cluster client configuration
addresses = [
    NodeAddress("localhost", 6379)
]
config = GlideClusterClientConfiguration(addresses)

# Initialize client
glideClusterClient = await GlideClusterClient.create(config)

# Configure retry strategy and pipeline options
retry_strategy = ClusterBatchRetryStrategy(
    retry_server_error=False,
    retry_connection_error=True
)

pipeline_options = ClusterBatchOptions(
    timeout=5000,                # 5-second timeout
    retry_strategy=retry_strategy
)

# Create pipeline spanning multiple slots
pipeline_cluster = ClusterBatch(False)  # False indicates non-atomic (pipeline)
pipeline_cluster.set("page:home:views", "100")
pipeline_cluster.incrby("page:home:views", 25)
pipeline_cluster.get("page:home:views")
pipeline_cluster.lpush("recent:logins", ["user1"])
pipeline_cluster.lpush("recent:logins", ["user2"])
pipeline_cluster.lrange("recent:logins", 0, 1)

# Execute with raise_on_error = False
pipeline_results = await glideClusterClient.exec(pipeline_cluster, raise_on_error=False, options=pipeline_options)
print("Pipeline Cluster Results:", pipeline_results)
# Expected output: Pipeline Cluster Results: ['OK', 125, '125', 1, 2, ['user2', 'user1']]
```

#### Multi-Node Support

While atomic batches (transactions) are restricted to a single Valkey node— all commands must map to the same hash slot in cluster mode—non-atomic batches (pipelines) can span multiple nodes. This enables operations that involve keys located in different slots or even multi-node commands.

When Glide processes a pipeline:

1. **Slot Calculation and Routing:** For each key-based command (e.g., `GET`, `SET`), Glide computes the hash slot and determines which node owns that slot. If a command does not reference a key (e.g., `INFO`), it follows the command’s default request policy.
2. **Grouping into Sub-Pipelines:** Commands targeting the same node are grouped together into a sub-pipeline. Each sub-pipeline contains all commands destined for a specific node.
3. **Dispatching Sub-Pipelines:** Glide sends each sub-pipeline independently to its target node as a pipelined request.
4. **Aggregating Responses:** Once all sub-pipelines return their results, Glide reassembles the responses into a single array, preserving the original command order. Multi-node commands are automatically split and dispatched appropriately.

**Retry Strategy in Pipelines**

When errors occur during pipeline execution, Glide handles them efficiently and granularly — each command in the pipeline receives its own response, whether successful or not. This means pipeline execution is not all-or-nothing: some commands may succeed while others may return errors (See the ClusterBatchRetryStrategy configuration and error handling details in the [classes and API section](https://github.com/valkey-io/valkey-glide/wiki/Python-Wrapper#classes-and-api) for how to handle these errors programmatically).

Glide distinguishes between different types of errors and handles them as follows:

* **Redirection Errors (e.g., `MOVED` or `ASK`):**
    These are always handled automatically. Glide will update the topology map if needed and redirect the command to the appropriate node, regardless of the retry configuration.
* **Retriable Server Errors (e.g., `TRYAGAIN`):**
    If the `retryServerError` option is enabled in the batch's retry strategy, Glide will retry commands that fail with retriable server errors. <br>
    ⚠️ Retrying may cause out-of-order execution for commands targeting the same slot.
* **Connection Errors:**
    If the `retryConnectionError` option is enabled, Glide will retry the batch if a connection failure occurs. <br>
    ⚠️ Retrying after a connection error may result in duplicate executions, since the server might have already received and processed the request before the error occurred.

Retry strategies are currently supported only for **non-atomic (pipeline) cluster batches.** You can configure these using the `ClusterBatchRetryStrategy` options:

* `retryServerError:` Retry on server errors.
* `retryConnectionError:` Retry on connection failures.

**Example Scenario:**

Suppose you issue the following commands:

```
MGET key {key}:1
SET key "value"
```
When keys are empty, the result is expected to be:
```
[null, null]
OK
```

However, suppose the slot of `key` is migrating. In this case, both commands will return an `ASK` error and be redirected. 
Upon `ASK` redirection, a multi-key command (like `MGET`) may return a `TRYAGAIN` error (triggering a retry), while the `SET` command succeeds immediately. 
This can result in an unintended reordering of commands if the first command is retried after the slot stabilizes:
```
["value", null]
OK
```

#### Deprecation Notice

* **Deprecated Classes:** `Transaction` and `ClusterTransaction` are deprecated in Glide 2.0.
* **Replacement:** Use `Batch` or `ClusterBatch` with `isAtomic = true` to achieve transaction-like (atomic) behavior.
* **Migration Tips**:

    * Replace calls to `new Transaction()` with `new Batch(true)`.
    * Replace calls to `new ClusterTransaction()` with `new ClusterBatch(true)`.
    * Replace `client.exec(transaction)` with `client.exec(batch, raiseOnError)` or `client.exec(batch, raiseOnError, options)`.

### OpenTelemetry (GLIDE 2.0)

Observability is consistently one of the top feature requests by customers. Valkey GLIDE 2.0 introduces support for [OpenTelemetry (OTel)](https://opentelemetry.io/), enabling developers to gain deep insights into client-side performance and behavior in distributed systems.
OTel is an open source, vendor-neutral framework that provides APIs, SDKs, and tools for generating, collecting, and exporting telemetry data—such as traces, metrics, and logs. It supports multiple programming languages and integrates with various observability backends like Prometheus, Jaeger, and AWS CloudWatch.

#### How It Works

GLIDE's OpenTelemetry integration is designed to be both powerful and easy to adopt. Once an OTel collector endpoint is configured, GLIDE begins emitting default metrics and traces automatically—no additional code changes are required. This simplifies the path to observability best practices and minimizes disruption to existing workflows.

#### Metrics Overview

GLIDE emits several built-in metrics out of the box. These metrics can be used to build dashboards, configure alerts, and monitor performance trends:

* **Timeouts**: Number of requests that exceeded their timeout duration.
* **Retries**: Count of operations retried due to transient errors or topology changes.
* **Moved Errors**: Number of MOVED responses received, indicating key reallocation in the cluster.

These metrics are emitted to your configured OpenTelemetry collector and can be viewed in any supported backend (Prometheus, CloudWatch, etc.).

#### Tracing Integration

GLIDE creates a **trace span for each Valkey command**, giving detailed visibility into client-side performance. Each trace captures:

* The **entire command lifecycle**: from creation to completion or failure.
* A nested **`send_command` span**, measuring communication time with the Valkey server.
* A **status tag** indicating success or error for each span, helping you identify failure patterns.

This distinction helps developers separate client-side queuing latency from server communication delays, making it easier to troubleshoot performance issues.

**⚠ Note:**
Some advanced commands are not yet included in tracing instrumentation:
* The SCAN family of commands (SCAN, SSCAN, HSCAN, ZSCAN)
* Lua scripting commands (EVAL, EVALSHA)

Support for these commands will be added in a future version as we continue to expand tracing coverage.

Even with these exceptions, GLIDE 2.0 provides comprehensive insights across the vast majority of standard operations, making it easy to adopt observability best practices with minimal effort.

#### Getting Started

To begin collecting telemetry data with GLIDE 2.0:

* Set up an [OpenTelemetry Collector](https://opentelemetry.io/docs/collector/) to receive trace and metric data.
* Configure the GLIDE client with the endpoint to your collector.
* Alternatively, you can configure GLIDE to export telemetry data directly to a local file for development or debugging purposes, without requiring a running collector.

GLIDE does not export data directly to third-party services—instead, it sends data to your collector, which routes it to your backend (e.g., CloudWatch, Prometheus, Jaeger).

#### Supported Collector Protocols

You can configure the OTel collector endpoint using one of the following protocols:

* `http://` or `https://` - Send data via HTTP(S)
* `grpc://` - Use gRPC for efficient telemetry transmission
* `file://` - Write telemetry data to a local file (ideal for local dev/debugging)

#### Optional Parameters

When initializing OpenTelemetry, you can customize behavior using the `openTelemetryConfig` object.
**Note**: Both `traces` and `metrics` are optional—but **at least one must be provided** in the `openTelemetryConfig`. If neither is set, OpenTelemetry will not emit any data.

#### Tracing
```python
openTelemetryConfig.traces
```

* **endpoint** (required): The trace collector endpoint.
* **samplePercentage** (optional): Percentage (0–100) of commands to sample for tracing. Default: `1`.
  * For production, a low sampling rate (1–5%) is recommended to balance performance and insight.

#### Metrics
```python
openTelemetryConfig.metrics
```

* **endpoint** (required): The metrics collector endpoint.

#### Flush Interval
```python
openTelemetryConfig.flush_interval_ms
```

* (optional): Time in milliseconds between flushes to the collector. Default: `5000`.

#### File Exporter Details

If using `file://` as the endpoint:

* The path must begin with `file://`.
* If a directory is provided (or no file extension), data is written to `signals.json` in that directory.
* If a filename is included, it will be used as-is.
* The parent directory must already exist.
* Data is **appended**, not overwritten.

#### Validation Rules

* `flush_interval_ms` must be a positive integer.
* `sample_percentage` must be between 0 and 100.
* File exporter paths must start with `file://` and have an existing parent directory.
* Invalid configuration will throw an error synchronously when calling `OpenTelemetry.init()`.

⚠️ **Important**: `OpenTelemetry.init()` can only be called **once per process**. Subsequent calls will be ignored. To change configuration, restart the process.


#### Full Example (Python)
```python
   from glide import OpenTelemetry, OpenTelemetryConfig, OpenTelemetryTracesConfig, OpenTelemetryMetricsConfig

        OpenTelemetry.init(OpenTelemetryConfig(
            traces=OpenTelemetryTracesConfig(
                endpoint="http://localhost:4318/v1/traces",
                sample_percentage=10  # Optional, defaults to 1. Can also be changed at runtime via set_sample_percentage().
            ),
            metrics=OpenTelemetryMetricsConfig(
                endpoint="http://localhost:4318/v1/metrics"
            ),
            flush_interval_ms=1000  # Optional, defaults to 5000
        ))
```

